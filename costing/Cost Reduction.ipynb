{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd5f1b2",
   "metadata": {},
   "source": [
    "## Cost Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3772a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.llms import OpenAI\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da9959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee6f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key  = os.environ['OPANAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd4b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the caching really obvious, lets use a slower model.\n",
    "llm = OpenAI(openai_api_key=openai_api_key, model_name=\"text-davinci-002\", n=2, best_of=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eaf825",
   "metadata": {},
   "source": [
    "Let's setup some decorator to help use calculate the time to see the impact of using a decorator and not using one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa22235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_complete(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        start = timer()\n",
    "        func(*args, **kwargs)\n",
    "        end = timer()\n",
    "\n",
    "        print(f\"Time taken to complete: {end - start}\")\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aae9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_to_complete\n",
    "def run(llm, args):\n",
    "    llm(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e22ee9",
   "metadata": {},
   "source": [
    "### In Memory Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f9fe8",
   "metadata": {},
   "source": [
    "Run without the caching implemeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736d145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"How far is the Earth from the Sun?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53bf04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe Earth is about 93 million miles from the Sun.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3b5f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete: 0.7098099169961642\n"
     ]
    }
   ],
   "source": [
    "run(llm, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b93aa7",
   "metadata": {},
   "source": [
    "Implement caching in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14964053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f28afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2cdea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe Earth is about 93 million miles from the Sun.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50803c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete: 0.00023501500254496932\n"
     ]
    }
   ],
   "source": [
    "run(llm, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f392c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448ffd8",
   "metadata": {},
   "source": [
    "### SQLite Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45eef540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec18773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete: 0.6895445980044315\n"
     ]
    }
   ],
   "source": [
    "run(llm, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff7650e",
   "metadata": {},
   "source": [
    "After implementation of caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2613ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = SQLiteCache(database_path=\".testDB.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc0f4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete: 0.00644729399937205\n"
     ]
    }
   ],
   "source": [
    "run(llm, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d289ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62cae8",
   "metadata": {},
   "source": [
    "### GTPCaching\n",
    "\n",
    "There are two main ways of using the **GTPCaching**, these are:\n",
    "\n",
    "1. **Exact matching**\n",
    "\n",
    "2. **Semantic Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d1ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gptcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c65b8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptcache import Cache\n",
    "from gptcache.manager.factory import manager_factory\n",
    "from gptcache.processor.pre import get_prompt\n",
    "from langchain.cache import GPTCache\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca7cb3",
   "metadata": {},
   "source": [
    "#### Exact Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b785aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashed_name(name):\n",
    "    return hashlib.sha256(name.encode()).hexdigest()\n",
    "\n",
    "\n",
    "def init_gptcache(cache_obj: Cache, llm: str):\n",
    "    hashed_llm = get_hashed_name(llm)\n",
    "    cache_obj.init(\n",
    "        pre_embedding_func=get_prompt,\n",
    "        data_manager=manager_factory(manager=\"map\", data_dir=f\"map_cache_{hashed_llm}\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cabfb3f",
   "metadata": {},
   "source": [
    "Before introducing caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d850888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete: 0.7874066430085804\n"
     ]
    }
   ],
   "source": [
    "run(llm, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a4f18f",
   "metadata": {},
   "source": [
    "Now, let's introduce caching and measure the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e963374",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = GPTCache(init_gptcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3c85f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete: 0.002098513999953866\n"
     ]
    }
   ],
   "source": [
    "run(llm, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc17293",
   "metadata": {},
   "source": [
    "#### Semantic Similarity Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76fd26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptcache.adapter.api import init_similar_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0302542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashed_name(name):\n",
    "    return hashlib.sha256(name.encode()).hexdigest()\n",
    "\n",
    "\n",
    "def init_gptcache(cache_obj: Cache, llm: str):\n",
    "    hashed_llm = get_hashed_name(llm)\n",
    "    init_similar_cache(cache_obj=cache_obj, data_dir=f\"similar_cache_{hashed_llm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff540d8",
   "metadata": {},
   "source": [
    "Before caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "778bb6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete: 0.00039819600351620466\n"
     ]
    }
   ],
   "source": [
    "run(llm, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eed551",
   "metadata": {},
   "source": [
    "Now, let's introduce caching and measure the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09a3a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = GPTCache(init_gptcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78f64434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete: 2.1773721140052658\n"
     ]
    }
   ],
   "source": [
    "run(llm, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fff75b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
